
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">


<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />


<title>Jiangtao Feng</title>

</head>


<body>
<div id="docbase">

<div id="header">
<a href="index.html">
</a>
  <center>
<h1><a href="./index.html">Jiangtao Feng (封江涛)</a></h1>
  </center>
</div>

<table border="0" cellpadding="5" cellspacing="10">
<tbody><tr>
<td valign="middle">
<img src="jiangtaofeng2022.jpg" height="180">
</td>
<td valign="middle">
<p>
  Currently, I am a research engineer affiliated with <a href="https://github.com/Shark-NLP">Shanghai Ark NLP (Shark NLP)</a>, <a href="https://www.shlab.org.cn">Shanghai AI Lab</a>.
  Previously, I worked as a researcher at <a href="https://ailab.bytedance.com">Bytedance AI Lab</a>.
  I also interned at <a href="https://ai.google">Google AI China Center</a>.
  I spent seven years at <a href="https://www.fudan.edu.cn/">Fudan University</a>
  pursuing my bachelor and master degrees, under the supervision by
  <a href="https://faculty.fudan.edu.cn/zhengxq/zh_CN/index/155051/list/index.htm">Prof. Xiaoqing Zheng</a>.
</p>
<p>
  My research focuses on text generation and generative models. Currently, I feel interested in (large) language models on their backbone architectures, pretraining and instruction tuning.
</p>
<p>
  Welcome to have a chat!
</p>
<p></p>
<p><b>Email</b>: fengjiangtao@pjlab.org.cn, fengjt16@fudan.edu.cn </p>
</td>
  </tr>
</tbody></table>

<h3><b>Softwares</b></h3>
<ul class="decimal">
  <li>
    <a href="https://arxiv.org/abs/2303.02913">OpenICL</a>
    <a href="https://github.com/Shark-NLP/OpenICL"><img alt="GitHub Stars" src="https://img.shields.io/github/stars/Shark-NLP/OpenICL?style=social"></a>: an open-source framework to facilitate research, development, and prototyping of in-context learning..
  </li>
  <li>
    <a href="https://arxiv.org/abs/2210.03405">ParaGen</a>
    <a href="https://github.com/bytedance/ParaGen"><img alt="GitHub Stars" src="https://img.shields.io/github/stars/bytedance/ParaGen?style=social"></a>: a PyTorch deep learning framework for parallel sequence generation and beyond.
  </li>
</ul>

<h3><b>Research Highlights</b> (<a href="https://scholar.google.com/citations?user=7ufSFeIAAAAJ&hl=en" target="_blank">Google Scholar</a>)</h3>

<ul class="decimal">
  <li>
    Long-Range Language Modeling
    <ul>
      <li><a href="https://arxiv.org/pdf/2302.04931v1.pdf">In-Context Learning with Many Demonstration Examples</a>, arXiv:2302.04931</li>
    </ul>
    <ul>
      <li><a href="https://arxiv.org/pdf/2210.07661.pdf">CAB: Comprehensive Attention Benchmarking on Long Sequence Modeling</a>, arXiv:2210.07661</li>
    </ul>
  </li>
  <li>
    Text generation & neural machine translation
    <ul>
      <li><a href="https://arxiv.org/abs/2205.14690">CoNT: Contrastive Neural Text Generation</a>, NeurIPS 2022 <b style="color:Tomato;">(Spotlight)</b></li>
      <li><a href="https://aclanthology.org/2021.wmt-1.17/">The Volctrans GLAT System: Non-autoregressive Translation Meets WMT21</a>, WMT 2021 <b style="color:Tomato;">(De-En champion)</b></li>
    </ul>
  </li>
  <li>
    Generative models for sequence modeling
    <ul>
      <li><a href="https://arxiv.org/pdf/2210.08933.pdf">DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models</a>, ICLR 2023</li>
      <li><a href="https://arxiv.org/abs/1811.02172">Neural Phrase-to-Phrase Machine Translation</a>, arXiv:1811.02172</li>
    </ul>
  </li>
  <li>
    Contextualized word representation learning
    <ul>
      <li><a href="https://ojs.aaai.org/index.php/AAAI/article/view/11986">Geometric Relationship between Word and Context Representations</a>, AAAI 2018 <b style="color:Tomato;">(Oral)</b></li>
      <li><a href="https://ojs.aaai.org/index.php/AAAI/article/view/10985">Learning Context-Specific Word/Character Embeddings</a>, AAAI 2017</li>
    </ul>
  </li>
</ul>


<h3><b>Prizes &#38; Awards</b></h3>
<ul>
<li>Outstanding Graduate in Shanghai, 2019</li>
<li>China National Scholarship, 2016-2017 &#38; 2017-2018</li>
<li>Outstanding Undergraduation Thesis of Software School in Fudan University, 2016</li>
<li>1st Prize in 2014 National Undergraduate Mathematical Contest in Modeling, 2014</li>
<li>1st Prize in 2013 Shanghai Undergraduate Mathematical Contest, 2013</li>
</ul>

</div>
</body>


</html>
